{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Artificial neural networks are models inspired by networks of biological neurons that are made up of artificial neurons that individually perform various computations.\n",
    "\n",
    "Topics:\n",
    "\n",
    "- Overview\n",
    "- Implementation\n",
    "- Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "One simple ANN architecture is the **Perceptron**, which is made up of a single layer of **threshold logic units (TLUs)**. A TLU computes a weighted sum of inputs and applies a step function to determine an output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Equation 1: Common step functions*\n",
    "\n",
    "\\begin{equation*}\n",
    "\\text{heaviside}(z) = \\begin{cases}\n",
    "0 \\;\\text{ if }\\; z \\lt t\\\\\n",
    "1 \\;\\text{ if }\\; z \\geq t\\\\\n",
    "\\end{cases}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "\\text{sgn}(z) = \\begin{cases}\\begin{aligned}\n",
    "-1 \\;\\text{ if }\\; z \\lt t\\\\\n",
    "0 \\;\\text{ if }\\; z = t\\\\\n",
    "1 \\;\\text{ if }\\; z \\geq t\\\\\n",
    "\\end{aligned}\\end{cases}\n",
    "\\end{equation*}\n",
    "\n",
    "where $t$ is some numeric threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each TLU in a Perceptron is connected to all of the inputs in the input layer, classifying the Perceptron as a **fully connected layer**. Constant inputs are referred to as **bias neurons**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Equation 2: Computing fully connected layer outputs*\n",
    "\n",
    "\\begin{equation*}\n",
    "h_\\mathbf{W},\\mathbf{b}(\\mathbf{X}) = \\phi(\\mathbf{XW}+\\mathbf{b})\n",
    "\\end{equation*}\n",
    "\n",
    "- $\\mathbf{X}$ is the matrix of input features\n",
    "- $\\mathbf{W}$ is the vector of non-bias connectionn weights\n",
    "- $\\mathbf{b}$ is the vector of bias connection weights\n",
    "- $\\phi$ is the activation function (such as a step function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a Perceptron involves adjusting the weights after making predictions on each training instance to reduce the error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Equation 3: Perceptron learning rule*\n",
    "\n",
    "\\begin{equation*}\n",
    "w_{i,j}^{\\text{next step}} = w_{i,j} + \\eta  \\bigl(y_j - \\hat{y}_j\\bigr)x_i\n",
    "\\end{equation*}\n",
    "\n",
    "- $w_{i,j}$ is the connection weight between the $i^{\\text{th}}$ input neuron and the $j^{\\text{th}}$ output neuron\n",
    "- $x_i$ is the $i^{\\text{th}}$ input value of the current training instance\n",
    "- $\\hat{y}_j$ is the output of the $j^{\\text{th}}$ output neuron for the current training instance\n",
    "- $y_j$ is the target output of the $j^{\\text{th}}$ output neuron for the current training instance\n",
    "- $\\eta$ is the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
       "           fit_intercept=True, max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "           penalty=None, random_state=0, shuffle=True, tol=0.001,\n",
       "           validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perceptron demonstration with sklearn\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "# Get petal length and width\n",
    "X = iris.data[:, (2, 3)]\n",
    "y = (iris.target == 0).astype(np.int)\n",
    "\n",
    "per_clf = Perceptron()\n",
    "per_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = per_clf.predict([[2, 0.5]])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Multilayer Perceptron (MLP) is composed of one input layer, one or more hidden layers containing TLUs, and an output layer of TLUs. An artificial neural network that contains several hidden layers is considered a deep neural network (DNN).\n",
    "\n",
    "The backpropagation algorithm is a common training algorithm for layered networks. It works by passing batches of data through the layers and preserving the intermediate results, computing the output error, determining how each intermediate result contributed to the error in the following layer, and performing Gradient Descent to tweak each weight to reduce the error at each step. Each full pass of a batch is referred to as an epoch.\n",
    "\n",
    "Since the step function has no derivative, it is incompatible with Gradient Descent, and other activation functions must be used. Some options include:\n",
    "\n",
    "- The logistic  sigmoid function: $\\sigma(z) = 1/(1+\\text{exp}(-z))$\n",
    "- The hyperbolic tangent function: $tanh(z) = 2\\sigma(2z)-1$\n",
    "- The rectified linear unit function (ReLU): $\\text{ReLU}(z) = max(0, z)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "Keras has three APIs for building models: the Sequential API, the Functional API, and the Subclassing API. Each of the following sections will demonstrate one of them.\n",
    "\n",
    "### Classification (Sequential API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Use Fashion MNIST dataset\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "\n",
    "# Split into test and train sets\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), dtype('uint8'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape, X_train_full.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize, separate validation and train sets\n",
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish class names\n",
    "class_names = [\n",
    "    'T-shirt/top',\n",
    "    'Trouser',\n",
    "    'Pullover',\n",
    "    'Dress',\n",
    "    'Coat',\n",
    "    'Sandal',\n",
    "    'Shirt',\n",
    "    'Sneaker',\n",
    "    'Bag',\n",
    "    'Ankle boot'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X_train[0], cmap=\"binary\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear existing session\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# Sequential model, single stack of layers connected sequentially\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "# Flatten each input to a 1D array\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "\n",
    "# Two dense hidden layers, relu as it's usually the default\n",
    "model.add(keras.layers.Dense(300, activation='relu'))\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "\n",
    "# Dense output layer with one output per class, softmax for exclusive classification\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "# Alternatively, initialize the model with list of layers\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation='relu'),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# View the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0x1daff98cac8>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1daffa22648>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1daffa227c8>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1daffa22ec8>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the list of layers\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access layers by name or index\n",
    "model.get_layer('dense') is model.layers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.05135491,  0.0093123 , -0.04415404, ..., -0.00132608,\n",
       "         -0.06461485, -0.0686061 ],\n",
       "        [-0.04437665, -0.0099875 , -0.00919275, ...,  0.00827672,\n",
       "          0.03127936, -0.02838699],\n",
       "        [-0.05012524,  0.05122694,  0.0237115 , ...,  0.00583497,\n",
       "          0.06205806, -0.04497433],\n",
       "        ...,\n",
       "        [ 0.01310103,  0.02924064,  0.00442895, ...,  0.05478485,\n",
       "         -0.04044497, -0.02812814],\n",
       "        [-0.05405405,  0.03119689,  0.03655479, ..., -0.01992878,\n",
       "         -0.04658104, -0.06543028],\n",
       "        [ 0.04888155, -0.04975817, -0.04395811, ..., -0.02314116,\n",
       "         -0.01381786,  0.01610918]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access weights and biases\n",
    "weights, biases = model.get_layer('dense').get_weights()\n",
    "weights, biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model to specify loss function and optimizer\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: sparse_categorical_crossentropy is used for exclusive classification. If one-hot vectors are desired, categorical_crossentropy should be used instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "55000/55000 [==============================] - 8s 150us/sample - loss: 0.7307 - accuracy: 0.7588 - val_loss: 0.5401 - val_accuracy: 0.8176\n",
      "Epoch 2/30\n",
      "55000/55000 [==============================] - 9s 159us/sample - loss: 0.4952 - accuracy: 0.8260 - val_loss: 0.4473 - val_accuracy: 0.8490\n",
      "Epoch 3/30\n",
      "55000/55000 [==============================] - 8s 143us/sample - loss: 0.4496 - accuracy: 0.8421 - val_loss: 0.4418 - val_accuracy: 0.8478\n",
      "Epoch 4/30\n",
      "55000/55000 [==============================] - 8s 142us/sample - loss: 0.4196 - accuracy: 0.8528 - val_loss: 0.3939 - val_accuracy: 0.8678\n",
      "Epoch 5/30\n",
      "55000/55000 [==============================] - 7s 126us/sample - loss: 0.3994 - accuracy: 0.8595 - val_loss: 0.3855 - val_accuracy: 0.8678\n",
      "Epoch 6/30\n",
      "55000/55000 [==============================] - 6s 115us/sample - loss: 0.3819 - accuracy: 0.8652 - val_loss: 0.3765 - val_accuracy: 0.8688\n",
      "Epoch 7/30\n",
      "55000/55000 [==============================] - 6s 115us/sample - loss: 0.3674 - accuracy: 0.8703 - val_loss: 0.3823 - val_accuracy: 0.8616\n",
      "Epoch 8/30\n",
      "55000/55000 [==============================] - 7s 119us/sample - loss: 0.3554 - accuracy: 0.8737 - val_loss: 0.3636 - val_accuracy: 0.8742\n",
      "Epoch 9/30\n",
      "55000/55000 [==============================] - 7s 119us/sample - loss: 0.3452 - accuracy: 0.8768 - val_loss: 0.3482 - val_accuracy: 0.8790\n",
      "Epoch 10/30\n",
      "55000/55000 [==============================] - 7s 120us/sample - loss: 0.3358 - accuracy: 0.8804 - val_loss: 0.3483 - val_accuracy: 0.8786\n",
      "Epoch 11/30\n",
      "55000/55000 [==============================] - 7s 119us/sample - loss: 0.3270 - accuracy: 0.8829 - val_loss: 0.3461 - val_accuracy: 0.8772\n",
      "Epoch 12/30\n",
      "55000/55000 [==============================] - 7s 132us/sample - loss: 0.3197 - accuracy: 0.8851 - val_loss: 0.3383 - val_accuracy: 0.8806\n",
      "Epoch 13/30\n",
      "55000/55000 [==============================] - 8s 137us/sample - loss: 0.3120 - accuracy: 0.8889 - val_loss: 0.3298 - val_accuracy: 0.8844\n",
      "Epoch 14/30\n",
      "55000/55000 [==============================] - 8s 137us/sample - loss: 0.3043 - accuracy: 0.8909 - val_loss: 0.3418 - val_accuracy: 0.8814\n",
      "Epoch 15/30\n",
      "55000/55000 [==============================] - 8s 141us/sample - loss: 0.2981 - accuracy: 0.8929 - val_loss: 0.3358 - val_accuracy: 0.8778\n",
      "Epoch 16/30\n",
      "55000/55000 [==============================] - 8s 143us/sample - loss: 0.2923 - accuracy: 0.8944 - val_loss: 0.3247 - val_accuracy: 0.8804\n",
      "Epoch 17/30\n",
      "55000/55000 [==============================] - 8s 141us/sample - loss: 0.2870 - accuracy: 0.8962 - val_loss: 0.3183 - val_accuracy: 0.8846\n",
      "Epoch 18/30\n",
      "55000/55000 [==============================] - 10s 176us/sample - loss: 0.2805 - accuracy: 0.8991 - val_loss: 0.3332 - val_accuracy: 0.8804\n",
      "Epoch 19/30\n",
      "55000/55000 [==============================] - 6s 113us/sample - loss: 0.2759 - accuracy: 0.9011 - val_loss: 0.3093 - val_accuracy: 0.8884\n",
      "Epoch 20/30\n",
      "55000/55000 [==============================] - 4s 80us/sample - loss: 0.2717 - accuracy: 0.9027 - val_loss: 0.3102 - val_accuracy: 0.8870\n",
      "Epoch 21/30\n",
      "55000/55000 [==============================] - 4s 81us/sample - loss: 0.2660 - accuracy: 0.9046 - val_loss: 0.3129 - val_accuracy: 0.8852\n",
      "Epoch 22/30\n",
      "55000/55000 [==============================] - 4s 81us/sample - loss: 0.2611 - accuracy: 0.9067 - val_loss: 0.3032 - val_accuracy: 0.8894\n",
      "Epoch 23/30\n",
      "55000/55000 [==============================] - 5s 87us/sample - loss: 0.2567 - accuracy: 0.9080 - val_loss: 0.3135 - val_accuracy: 0.8870\n",
      "Epoch 24/30\n",
      "55000/55000 [==============================] - 4s 80us/sample - loss: 0.2522 - accuracy: 0.9098 - val_loss: 0.2988 - val_accuracy: 0.8942\n",
      "Epoch 25/30\n",
      "55000/55000 [==============================] - 4s 78us/sample - loss: 0.2479 - accuracy: 0.9100 - val_loss: 0.3100 - val_accuracy: 0.8908\n",
      "Epoch 26/30\n",
      "55000/55000 [==============================] - 4s 79us/sample - loss: 0.2442 - accuracy: 0.9126 - val_loss: 0.3133 - val_accuracy: 0.8908\n",
      "Epoch 27/30\n",
      "55000/55000 [==============================] - 4s 78us/sample - loss: 0.2398 - accuracy: 0.9134 - val_loss: 0.3007 - val_accuracy: 0.8928\n",
      "Epoch 28/30\n",
      "55000/55000 [==============================] - 4s 78us/sample - loss: 0.2363 - accuracy: 0.9134 - val_loss: 0.2976 - val_accuracy: 0.8898\n",
      "Epoch 29/30\n",
      "55000/55000 [==============================] - 4s 79us/sample - loss: 0.2322 - accuracy: 0.9162 - val_loss: 0.3250 - val_accuracy: 0.8822\n",
      "Epoch 30/30\n",
      "55000/55000 [==============================] - 5s 84us/sample - loss: 0.2290 - accuracy: 0.9178 - val_loss: 0.3106 - val_accuracy: 0.8882\n"
     ]
    }
   ],
   "source": [
    "# Training the model returns a History object\n",
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1daffa99708>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# The history can be plotted to observe the accuracy and loss over time\n",
    "pd.DataFrame(history.history).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 134us/sample - loss: 75.0967 - accuracy: 0.8297\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[75.09674187389612, 0.8297]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_test[:3]\n",
    "\n",
    "# Get probabilities for each class\n",
    "y_proba = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([9, 2, 1], dtype=int64),\n",
       " array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11'))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get just the highest probability\n",
    "y_pred = model.predict_classes(X_new)\n",
    "y_pred, np.array(class_names)[y_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression (Sequential API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Use the California housing dataset\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "# Separate into train, test, and validation sets\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    # Use a shallow network to avoid overfitting the noisy data\n",
    "    keras.layers.Dense(30, activation='relu', input_shape=X_train.shape[1:]),\n",
    "    # Only one output neuron to return a single value\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Mean squared error loss function for regression\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 2s 180us/sample - loss: 0.7915 - val_loss: 1.0373\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 2s 139us/sample - loss: 0.5315 - val_loss: 1.0358\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 2s 140us/sample - loss: 0.4772 - val_loss: 2.2254\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 2s 139us/sample - loss: 0.4638 - val_loss: 3.2531\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 2s 137us/sample - loss: 0.4573 - val_loss: 0.4497\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 2s 137us/sample - loss: 0.4116 - val_loss: 0.4159\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 2s 139us/sample - loss: 0.3986 - val_loss: 0.3980\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 2s 147us/sample - loss: 0.3893 - val_loss: 0.4024\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 2s 142us/sample - loss: 0.3855 - val_loss: 0.3925\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 2s 140us/sample - loss: 0.3784 - val_loss: 0.4078\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 2s 137us/sample - loss: 0.3818 - val_loss: 0.4286\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 2s 139us/sample - loss: 0.3826 - val_loss: 0.4552\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 2s 149us/sample - loss: 0.3710 - val_loss: 0.3929\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 2s 137us/sample - loss: 0.3661 - val_loss: 0.3940\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 2s 136us/sample - loss: 0.3655 - val_loss: 0.3886\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 2s 136us/sample - loss: 0.3582 - val_loss: 0.4166\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 2s 137us/sample - loss: 0.3665 - val_loss: 0.4236\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 2s 139us/sample - loss: 0.3835 - val_loss: 0.4064\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 2s 139us/sample - loss: 0.3601 - val_loss: 0.3989\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 2s 142us/sample - loss: 0.3691 - val_loss: 0.4017\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 77us/sample - loss: 0.3689\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.36891114328258723"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the mean squared error of the test set\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.9467266],\n",
       "       [1.2225099],\n",
       "       [1.4793062]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nonsequential Models (Functional API)\n",
    "\n",
    "One example of a nonsequential neural network is a **Wide & Deep** network, which connects some (or all) of the input layer to the output layer. This enables the network to learn patterns from the long (deep) path and simple rules from the short (wide) path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the input layer shape\n",
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "\n",
    "# Immediately call the hidden layers with the preceding layers to connect them\n",
    "hidden1 = keras.layers.Dense(30, activation='relu')(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
    "\n",
    "# Connect the input layer to the output of the second hidden layer\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])\n",
    "\n",
    "# Connect the output layer to the output of the concatenation\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "\n",
    "# Create the model, specifying the input and output layers\n",
    "model = keras.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 2s 211us/sample - loss: 2.1924 - val_loss: 88.6711\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 2s 151us/sample - loss: 2.4754 - val_loss: 11.7280\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 2s 146us/sample - loss: nan - val_loss: nan\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 2s 146us/sample - loss: nan - val_loss: nan\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 2s 146us/sample - loss: nan - val_loss: nan\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 2s 147us/sample - loss: nan - val_loss: nan\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 2s 146us/sample - loss: nan - val_loss: nan\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 2s 148us/sample - loss: nan - val_loss: nan\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 2s 146us/sample - loss: nan - val_loss: nan\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 2s 145us/sample - loss: nan - val_loss: nan\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 2s 146us/sample - loss: nan - val_loss: nan\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 2s 146us/sample - loss: nan - val_loss: nan\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 2s 146us/sample - loss: nan - val_loss: nan\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 2s 146us/sample - loss: nan - val_loss: nan\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 2s 146us/sample - loss: nan - val_loss: nan\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 2s 146us/sample - loss: nan - val_loss: nan\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 2s 146us/sample - loss: nan - val_loss: nan\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 2s 147us/sample - loss: nan - val_loss: nan\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 2s 147us/sample - loss: nan - val_loss: nan\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 2s 147us/sample - loss: nan - val_loss: nan\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model clearly diverged early in the training. A Wide & Deep network may help solve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape to add features 0-4 to the wide path\n",
    "input_A = keras.layers.Input(shape=[5], name='wide_input')\n",
    "\n",
    "# Shape to add features 2-7 to the deep path\n",
    "input_B = keras.layers.Input(shape=[6], name='deep_input')\n",
    "\n",
    "# Connect hidden layers\n",
    "hidden1 = keras.layers.Dense(30, activation='relu')(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
    "\n",
    "# Concatenate as before\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name='output')(concat)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another form of the previous compile\n",
    "model.compile(loss='mse', optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data for inputs A and B\n",
    "split_a_b = lambda x: (x[:, :5], x[:, 2:])\n",
    "\n",
    "X_train_a_b = split_a_b(X_train)\n",
    "X_valid_a_b = split_a_b(X_valid)\n",
    "X_test_a_b = split_a_b(X_test)\n",
    "\n",
    "X_new_a_b = X_test_a_b[0][:3], X_test_a_b[1][:3]\n",
    "\n",
    "# For more complicated networks, a dictionary of name:data can be used instead of tuples\n",
    "X_train_a_b_dict = dict(zip(['wide_input', 'deep_input'], split_a_b(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 2s 203us/sample - loss: 2.1348 - val_loss: 0.9410\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 2s 154us/sample - loss: 0.7838 - val_loss: 0.7221\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 2s 154us/sample - loss: 0.6790 - val_loss: 0.6576\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 2s 155us/sample - loss: 0.6367 - val_loss: 0.6221\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 2s 157us/sample - loss: 0.6086 - val_loss: 0.5976\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 2s 153us/sample - loss: 0.5855 - val_loss: 0.5766\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 2s 157us/sample - loss: 0.5672 - val_loss: 0.5578\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 2s 155us/sample - loss: 0.5505 - val_loss: 0.5463\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 2s 153us/sample - loss: 0.5404 - val_loss: 0.5353\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 2s 152us/sample - loss: 0.5301 - val_loss: 0.5273\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 2s 154us/sample - loss: 0.5234 - val_loss: 0.5191\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 2s 159us/sample - loss: 0.5164 - val_loss: 0.5138\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 2s 157us/sample - loss: 0.5107 - val_loss: 0.5085\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 2s 153us/sample - loss: 0.5055 - val_loss: 0.5043\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 2s 153us/sample - loss: 0.5006 - val_loss: 0.5006\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 2s 153us/sample - loss: 0.4974 - val_loss: 0.4958\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 2s 156us/sample - loss: 0.4937 - val_loss: 0.4934\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 2s 157us/sample - loss: 0.4901 - val_loss: 0.4899\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 2s 154us/sample - loss: 0.4877 - val_loss: 0.4872\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 2s 154us/sample - loss: 0.4850 - val_loss: 0.4850\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_a_b, y_train, epochs=20, validation_data=(X_valid_a_b, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 86us/sample - loss: 0.5077\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.1750535],\n",
       "       [2.8511384],\n",
       "       [1.0439118]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test_a_b, y_test)\n",
    "y_pred = model.predict(X_new_a_b)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases multiple outputs may desired:\n",
    "\n",
    "- Locating (regression) and classifying (classification) an object in a picture\n",
    "- Multitask classification (facial expressions, whether they're wearing glasses)\n",
    "- Regularization via auxiliary outputs to ensure the deep path is learning what it should"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As above\n",
    "input_A = keras.layers.Input(shape=[5], name='wide_input')\n",
    "input_B = keras.layers.Input(shape=[6], name='deep_input')\n",
    "hidden1 = keras.layers.Dense(30, activation='relu')(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "\n",
    "# Main output connencted to the output of the concatenation\n",
    "output = keras.layers.Dense(1, name='main_output')(concat)\n",
    "\n",
    "# Auxiliary output, connected to hidden2 before the concatenation\n",
    "aux_output = keras.layers.Dense(1, name='aux_output')(hidden2)\n",
    "\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output, aux_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include losses for both outputs, using dict method\n",
    "output_names = ['main_output', 'aux_output']\n",
    "output_losses = dict(zip(output_names, ['mse','mse']))\n",
    "output_weights = dict(zip(output_names, [0.9, 0.1]))\n",
    "\n",
    "model.compile(loss=output_losses, loss_weights=output_weights, optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 3s 283us/sample - loss: 0.9476 - main_output_loss: 0.8372 - aux_output_loss: 1.9391 - val_loss: 0.5801 - val_main_output_loss: 0.5113 - val_aux_output_loss: 1.1990\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 2s 215us/sample - loss: 0.5531 - main_output_loss: 0.4950 - aux_output_loss: 1.0767 - val_loss: 0.6403 - val_main_output_loss: 0.5951 - val_aux_output_loss: 1.0449\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 2s 209us/sample - loss: 0.5281 - main_output_loss: 0.4831 - aux_output_loss: 0.9330 - val_loss: 0.5090 - val_main_output_loss: 0.4642 - val_aux_output_loss: 0.9111\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 2s 209us/sample - loss: 0.5439 - main_output_loss: 0.5114 - aux_output_loss: 0.8357 - val_loss: 0.4947 - val_main_output_loss: 0.4578 - val_aux_output_loss: 0.8255\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 2s 211us/sample - loss: 0.4821 - main_output_loss: 0.4517 - aux_output_loss: 0.7568 - val_loss: 0.4738 - val_main_output_loss: 0.4431 - val_aux_output_loss: 0.7496\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 2s 210us/sample - loss: 0.4664 - main_output_loss: 0.4399 - aux_output_loss: 0.7037 - val_loss: 0.4631 - val_main_output_loss: 0.4357 - val_aux_output_loss: 0.7084\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 2s 210us/sample - loss: 0.4522 - main_output_loss: 0.4282 - aux_output_loss: 0.6698 - val_loss: 0.4473 - val_main_output_loss: 0.4221 - val_aux_output_loss: 0.6728\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 3s 218us/sample - loss: 0.4494 - main_output_loss: 0.4277 - aux_output_loss: 0.6443 - val_loss: 0.4426 - val_main_output_loss: 0.4195 - val_aux_output_loss: 0.6503\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 3s 217us/sample - loss: 0.4364 - main_output_loss: 0.4157 - aux_output_loss: 0.6218 - val_loss: 0.4272 - val_main_output_loss: 0.4054 - val_aux_output_loss: 0.6226\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 3s 218us/sample - loss: 0.4264 - main_output_loss: 0.4068 - aux_output_loss: 0.6032 - val_loss: 0.4194 - val_main_output_loss: 0.3988 - val_aux_output_loss: 0.6039\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 3s 217us/sample - loss: 0.4172 - main_output_loss: 0.3987 - aux_output_loss: 0.5823 - val_loss: 0.4143 - val_main_output_loss: 0.3946 - val_aux_output_loss: 0.5902\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 3s 221us/sample - loss: 0.4410 - main_output_loss: 0.4271 - aux_output_loss: 0.5653 - val_loss: 0.4103 - val_main_output_loss: 0.3916 - val_aux_output_loss: 0.5777\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 3s 220us/sample - loss: 0.4054 - main_output_loss: 0.3889 - aux_output_loss: 0.5538 - val_loss: 0.4011 - val_main_output_loss: 0.3829 - val_aux_output_loss: 0.5632\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 3s 222us/sample - loss: 0.3992 - main_output_loss: 0.3836 - aux_output_loss: 0.5378 - val_loss: 0.3894 - val_main_output_loss: 0.3719 - val_aux_output_loss: 0.5461\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 3s 219us/sample - loss: 0.3919 - main_output_loss: 0.3768 - aux_output_loss: 0.5277 - val_loss: 0.3830 - val_main_output_loss: 0.3663 - val_aux_output_loss: 0.5323\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 3s 218us/sample - loss: 0.3936 - main_output_loss: 0.3801 - aux_output_loss: 0.5152 - val_loss: 0.4454 - val_main_output_loss: 0.4338 - val_aux_output_loss: 0.5487\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 3s 220us/sample - loss: 0.3863 - main_output_loss: 0.3727 - aux_output_loss: 0.5098 - val_loss: 0.3815 - val_main_output_loss: 0.3659 - val_aux_output_loss: 0.5209\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 3s 225us/sample - loss: 0.3763 - main_output_loss: 0.3628 - aux_output_loss: 0.4973 - val_loss: 0.3727 - val_main_output_loss: 0.3570 - val_aux_output_loss: 0.5131\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 3s 221us/sample - loss: 0.3717 - main_output_loss: 0.3585 - aux_output_loss: 0.4904 - val_loss: 0.3672 - val_main_output_loss: 0.3524 - val_aux_output_loss: 0.4992\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 3s 225us/sample - loss: 0.3683 - main_output_loss: 0.3561 - aux_output_loss: 0.4829 - val_loss: 0.3611 - val_main_output_loss: 0.3465 - val_aux_output_loss: 0.4923\n"
     ]
    }
   ],
   "source": [
    "# Fit the model, including y_ sets for each output\n",
    "history = model.fit(X_train_a_b, [y_train, y_train], epochs=20, validation_data=(X_valid_a_b, [y_valid, y_valid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 1s 165us/sample - loss: 0.3839 - main_output_loss: 0.3749 - aux_output_loss: 0.4956\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.38389586723128033, 0.37486687, 0.49560943)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get total and separate losses\n",
    "total_loss, main_loss, aux_loss = model.evaluate(X_test_a_b, [y_test, y_test])\n",
    "total_loss, main_loss, aux_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.96850395],\n",
       "        [2.5149505 ],\n",
       "        [1.4132416 ]], dtype=float32), array([[0.8313312 ],\n",
       "        [1.8640378 ],\n",
       "        [0.94842786]], dtype=float32))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get both predictions\n",
    "y_pred_main, y_pred_aux = model.predict(X_new_a_b)\n",
    "y_pred_main, y_pred_aux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Models (Subclassing API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subclass for the wide & deep model\n",
    "class WideAndDeepModel(keras.Model):\n",
    "    def __init__(self, units=30, activation='relu', **kwargs):\n",
    "        # Handle standard arguments\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        # Initialize the model layers\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        # Establish the model architecture dynamically\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 3s 253us/sample - loss: 1.2033 - output_1_loss: 1.0610 - output_2_loss: 2.4808 - val_loss: 0.6346 - val_output_1_loss: 0.5495 - val_output_2_loss: 1.4003\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 3s 221us/sample - loss: 0.6569 - output_1_loss: 0.5858 - output_2_loss: 1.2950 - val_loss: 0.5849 - val_output_1_loss: 0.5076 - val_output_2_loss: 1.2793\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 2s 209us/sample - loss: 0.5647 - output_1_loss: 0.4981 - output_2_loss: 1.1650 - val_loss: 0.5403 - val_output_1_loss: 0.4733 - val_output_2_loss: 1.1421\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 2s 209us/sample - loss: 0.5233 - output_1_loss: 0.4662 - output_2_loss: 1.0368 - val_loss: 0.5188 - val_output_1_loss: 0.4617 - val_output_2_loss: 1.0311\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 2s 210us/sample - loss: 0.5028 - output_1_loss: 0.4544 - output_2_loss: 0.9368 - val_loss: 0.4988 - val_output_1_loss: 0.4502 - val_output_2_loss: 0.9344\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 2s 208us/sample - loss: 0.4871 - output_1_loss: 0.4464 - output_2_loss: 0.8523 - val_loss: 0.4792 - val_output_1_loss: 0.4389 - val_output_2_loss: 0.8410\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 2s 209us/sample - loss: 0.4689 - output_1_loss: 0.4349 - output_2_loss: 0.7733 - val_loss: 0.4712 - val_output_1_loss: 0.4386 - val_output_2_loss: 0.7634\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 3s 229us/sample - loss: 0.4571 - output_1_loss: 0.4281 - output_2_loss: 0.7166 - val_loss: 0.4516 - val_output_1_loss: 0.4219 - val_output_2_loss: 0.7176\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 3s 223us/sample - loss: 0.4442 - output_1_loss: 0.4186 - output_2_loss: 0.6756 - val_loss: 0.4924 - val_output_1_loss: 0.4697 - val_output_2_loss: 0.6952\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 3s 216us/sample - loss: 0.4370 - output_1_loss: 0.4140 - output_2_loss: 0.6468 - val_loss: 0.4295 - val_output_1_loss: 0.4052 - val_output_2_loss: 0.6474\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 2s 208us/sample - loss: 0.4244 - output_1_loss: 0.4027 - output_2_loss: 0.6225 - val_loss: 0.4328 - val_output_1_loss: 0.4118 - val_output_2_loss: 0.6205\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 2s 210us/sample - loss: 0.4300 - output_1_loss: 0.4107 - output_2_loss: 0.6033 - val_loss: 0.4130 - val_output_1_loss: 0.3915 - val_output_2_loss: 0.6050\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 2s 211us/sample - loss: 0.4085 - output_1_loss: 0.3887 - output_2_loss: 0.5864 - val_loss: 0.3980 - val_output_1_loss: 0.3775 - val_output_2_loss: 0.5806\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 2s 214us/sample - loss: 0.4005 - output_1_loss: 0.3815 - output_2_loss: 0.5705 - val_loss: 0.3997 - val_output_1_loss: 0.3803 - val_output_2_loss: 0.5732\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 3s 227us/sample - loss: 0.3924 - output_1_loss: 0.3739 - output_2_loss: 0.5574 - val_loss: 0.3889 - val_output_1_loss: 0.3699 - val_output_2_loss: 0.5582\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 2s 214us/sample - loss: 0.3855 - output_1_loss: 0.3677 - output_2_loss: 0.5445 - val_loss: 0.3978 - val_output_1_loss: 0.3797 - val_output_2_loss: 0.5591\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 2s 215us/sample - loss: 0.3829 - output_1_loss: 0.3661 - output_2_loss: 0.5340 - val_loss: 0.3775 - val_output_1_loss: 0.3600 - val_output_2_loss: 0.5336\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 2s 215us/sample - loss: 0.3766 - output_1_loss: 0.3601 - output_2_loss: 0.5244 - val_loss: 0.3811 - val_output_1_loss: 0.3646 - val_output_2_loss: 0.5280\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 2s 215us/sample - loss: 0.3736 - output_1_loss: 0.3578 - output_2_loss: 0.5162 - val_loss: 0.3654 - val_output_1_loss: 0.3484 - val_output_2_loss: 0.5173\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 3s 218us/sample - loss: 0.3708 - output_1_loss: 0.3553 - output_2_loss: 0.5099 - val_loss: 0.3574 - val_output_1_loss: 0.3410 - val_output_2_loss: 0.5037\n"
     ]
    }
   ],
   "source": [
    "model = WideAndDeepModel()\n",
    "\n",
    "# Compile and fit as above\n",
    "model.compile(loss=['mse', 'mse'], loss_weights=[0.9, 0.1], optimizer='sgd')\n",
    "history = model.fit(X_train_a_b, [y_train, y_train], epochs=20, validation_data=(X_valid_a_b, [y_valid, y_valid]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models created using the Sequential or Functional APIs can be saved in the HDF5 format for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 3s 236us/sample - loss: 0.8737 - val_loss: 0.6196\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 2s 147us/sample - loss: 0.7487 - val_loss: 0.4827\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 2s 149us/sample - loss: 0.4773 - val_loss: 0.4597\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 2s 152us/sample - loss: 0.4559 - val_loss: 0.4670\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 2s 147us/sample - loss: 0.4476 - val_loss: 0.4341\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 2s 141us/sample - loss: 0.4343 - val_loss: 0.4226\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 2s 146us/sample - loss: 0.4264 - val_loss: 0.4167\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 2s 143us/sample - loss: 0.4328 - val_loss: 0.4116\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 2s 141us/sample - loss: 0.4173 - val_loss: 0.4067\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 2s 140us/sample - loss: 0.4105 - val_loss: 0.4032\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 2s 139us/sample - loss: 0.4048 - val_loss: 0.3985\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 2s 141us/sample - loss: 0.4001 - val_loss: 0.3938\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 2s 141us/sample - loss: 0.3952 - val_loss: 0.3886\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 2s 148us/sample - loss: 0.3970 - val_loss: 0.3900\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 2s 141us/sample - loss: 0.3909 - val_loss: 0.3993\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 2s 141us/sample - loss: 0.3865 - val_loss: 0.3834\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 2s 142us/sample - loss: 0.3980 - val_loss: 0.3788\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 2s 141us/sample - loss: 0.3829 - val_loss: 0.4915\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 2s 140us/sample - loss: 0.3897 - val_loss: 0.4771\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 2s 140us/sample - loss: 0.3886 - val_loss: 0.3803\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    # Use a shallow network to avoid overfitting the noisy data\n",
    "    keras.layers.Dense(30, activation='relu', input_shape=X_train.shape[1:]),\n",
    "    # Only one output neuron to return a single value\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Mean squared error loss function for regression\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('pickles/keras_demo.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.651577],\n",
       "       [4.9775  ],\n",
       "       [7.072366]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model('pickles/keras_demo.h5')\n",
    "X_new = X_test[:3]\n",
    "model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models created with the Subclassing API can't be saved this way, but the save_weights and load_weights methods can still eliminate the need to retrain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Callbacks can be specified in the fit method to be executed at various points in the training process:\n",
    "\n",
    "- Start and end of training\n",
    "- Start and end of each epoch\n",
    "- Before and after processing each batch\n",
    "\n",
    "For example, ModelCheckpoint saves a checkpoint of the model at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples\n",
      "Epoch 1/10\n",
      "11610/11610 [==============================] - 2s 148us/sample - loss: 0.3897\n",
      "Epoch 2/10\n",
      "11610/11610 [==============================] - 1s 115us/sample - loss: 0.3818\n",
      "Epoch 3/10\n",
      "11610/11610 [==============================] - 1s 115us/sample - loss: 0.3721\n",
      "Epoch 4/10\n",
      "11610/11610 [==============================] - 1s 117us/sample - loss: 0.3749\n",
      "Epoch 5/10\n",
      "11610/11610 [==============================] - 1s 123us/sample - loss: 0.3677\n",
      "Epoch 6/10\n",
      "11610/11610 [==============================] - 1s 113us/sample - loss: 0.3662\n",
      "Epoch 7/10\n",
      "11610/11610 [==============================] - 1s 113us/sample - loss: 0.3676\n",
      "Epoch 8/10\n",
      "11610/11610 [==============================] - 1s 114us/sample - loss: 0.3726\n",
      "Epoch 9/10\n",
      "11610/11610 [==============================] - 1s 114us/sample - loss: 0.3843\n",
      "Epoch 10/10\n",
      "11610/11610 [==============================] - 1s 113us/sample - loss: 0.3673\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('pickles/keras_demo.h5')\n",
    "history = model.fit(X_train, y_train, epochs=10, callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "11610/11610 [==============================] - 2s 164us/sample - loss: 0.3624 - val_loss: 0.3557\n",
      "Epoch 2/10\n",
      "11610/11610 [==============================] - 2s 143us/sample - loss: 0.3578 - val_loss: 0.3610\n",
      "Epoch 3/10\n",
      "11610/11610 [==============================] - 2s 144us/sample - loss: 0.3583 - val_loss: 0.3561\n",
      "Epoch 4/10\n",
      "11610/11610 [==============================] - 2s 143us/sample - loss: 0.3601 - val_loss: 0.3633\n",
      "Epoch 5/10\n",
      "11610/11610 [==============================] - 2s 142us/sample - loss: 0.3568 - val_loss: 0.3540\n",
      "Epoch 6/10\n",
      "11610/11610 [==============================] - 2s 145us/sample - loss: 0.3547 - val_loss: 0.3526\n",
      "Epoch 7/10\n",
      "11610/11610 [==============================] - 2s 141us/sample - loss: 0.3922 - val_loss: 0.3611\n",
      "Epoch 8/10\n",
      "11610/11610 [==============================] - 2s 151us/sample - loss: 0.3503 - val_loss: 0.3484\n",
      "Epoch 9/10\n",
      "11610/11610 [==============================] - 2s 147us/sample - loss: 0.3491 - val_loss: 0.3506\n",
      "Epoch 10/10\n",
      "11610/11610 [==============================] - 2s 143us/sample - loss: 0.3498 - val_loss: 0.3440\n"
     ]
    }
   ],
   "source": [
    "# Only save the checkpoint if it scores better than the previously saved checkpoint\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('pickles/keras_demo.h5', save_best_only=True)\n",
    "\n",
    "# Include the validation set\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid), callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The EarlyStopping callback can be used to interrupt the training when no progress is made after some patience threshold, optionally rolling back to the highest scoring model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "11610/11610 [==============================] - 2s 158us/sample - loss: 0.3673 - val_loss: 0.3522\n",
      "Epoch 2/100\n",
      "11610/11610 [==============================] - 2s 141us/sample - loss: 0.3505 - val_loss: 0.3451\n",
      "Epoch 3/100\n",
      "11610/11610 [==============================] - 2s 142us/sample - loss: 0.3462 - val_loss: 0.3410\n",
      "Epoch 4/100\n",
      "11610/11610 [==============================] - 2s 142us/sample - loss: 0.3441 - val_loss: 0.3399\n",
      "Epoch 5/100\n",
      "11610/11610 [==============================] - 2s 147us/sample - loss: 0.3410 - val_loss: 0.3447\n",
      "Epoch 6/100\n",
      "11610/11610 [==============================] - 2s 144us/sample - loss: 0.3424 - val_loss: 0.3379\n",
      "Epoch 7/100\n",
      "11610/11610 [==============================] - 2s 141us/sample - loss: 0.3375 - val_loss: 0.3386\n",
      "Epoch 8/100\n",
      "11610/11610 [==============================] - 2s 142us/sample - loss: 0.3397 - val_loss: 0.3319\n",
      "Epoch 9/100\n",
      "11610/11610 [==============================] - 2s 144us/sample - loss: 0.4229 - val_loss: 0.3868\n",
      "Epoch 10/100\n",
      "11610/11610 [==============================] - 2s 142us/sample - loss: 0.3636 - val_loss: 0.3642\n",
      "Epoch 11/100\n",
      "11610/11610 [==============================] - 2s 146us/sample - loss: 0.3484 - val_loss: 0.3471\n",
      "Epoch 12/100\n",
      "11610/11610 [==============================] - 2s 142us/sample - loss: 0.3424 - val_loss: 0.3404\n",
      "Epoch 13/100\n",
      "11610/11610 [==============================] - 2s 142us/sample - loss: 0.3370 - val_loss: 0.3389\n",
      "Epoch 14/100\n",
      "11610/11610 [==============================] - 2s 140us/sample - loss: 0.3351 - val_loss: 0.3492\n",
      "Epoch 15/100\n",
      "11610/11610 [==============================] - 2s 144us/sample - loss: 0.3356 - val_loss: 0.3407\n",
      "Epoch 16/100\n",
      "11610/11610 [==============================] - 2s 146us/sample - loss: 0.3332 - val_loss: 0.3338\n",
      "Epoch 17/100\n",
      "11610/11610 [==============================] - 2s 147us/sample - loss: 0.3326 - val_loss: 0.3326\n",
      "Epoch 18/100\n",
      "11610/11610 [==============================] - 2s 151us/sample - loss: 0.3315 - val_loss: 0.3296\n",
      "Epoch 19/100\n",
      "11610/11610 [==============================] - 2s 148us/sample - loss: 0.3301 - val_loss: 0.3341\n",
      "Epoch 20/100\n",
      "11610/11610 [==============================] - 2s 149us/sample - loss: 0.3282 - val_loss: 0.3248\n",
      "Epoch 21/100\n",
      "11610/11610 [==============================] - 2s 141us/sample - loss: 0.3276 - val_loss: 0.3274\n",
      "Epoch 22/100\n",
      "11610/11610 [==============================] - 2s 148us/sample - loss: 0.3297 - val_loss: 0.3261\n",
      "Epoch 23/100\n",
      "11610/11610 [==============================] - 2s 143us/sample - loss: 0.3268 - val_loss: 0.3292\n",
      "Epoch 24/100\n",
      "11610/11610 [==============================] - 2s 140us/sample - loss: 0.3596 - val_loss: 0.3588\n",
      "Epoch 25/100\n",
      "11610/11610 [==============================] - 2s 144us/sample - loss: 0.3344 - val_loss: 0.3398\n",
      "Epoch 26/100\n",
      "11610/11610 [==============================] - 2s 141us/sample - loss: 0.3303 - val_loss: 0.3324\n",
      "Epoch 27/100\n",
      "11610/11610 [==============================] - 2s 141us/sample - loss: 0.3267 - val_loss: 0.3315\n",
      "Epoch 28/100\n",
      "11610/11610 [==============================] - 2s 152us/sample - loss: 0.3256 - val_loss: 0.3293\n",
      "Epoch 29/100\n",
      "11610/11610 [==============================] - 2s 143us/sample - loss: 0.3295 - val_loss: 0.3314\n",
      "Epoch 30/100\n",
      "11610/11610 [==============================] - 2s 141us/sample - loss: 0.3274 - val_loss: 0.3299\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid), callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, epoch 20 will be used because none of the 10 subsequent epochs had a better val_loss.\n",
    "\n",
    "Custom callbacks may also be defined, including behaviors for the following during training:\n",
    "\n",
    "- on_train_begin()\n",
    "- on_train_end()\n",
    "- on_epoch_begin()\n",
    "- on_epoch_end()\n",
    "- on_batch_begin()\n",
    "- on_batch_end()\n",
    "- on_test_begin()\n",
    "- on_test_end()\n",
    "\n",
    "...during evaluation, called by evaluate():\n",
    "\n",
    "- on_test_begin()\n",
    "- on_test_end()\n",
    "- on_test_batch_begin()\n",
    "- on_test__batch_end()\n",
    "\n",
    "...and during prediction, called by predict():\n",
    "\n",
    "- on_predict_begin()\n",
    "- on_predict_end()\n",
    "- on_predict_batch_begin()\n",
    "- on_predict_batch_end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the ratio between validation and training losses at each epoch to detect overfitting\n",
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(f\"\\nval/train: {(logs['val_loss']/logs['loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "11392/11610 [============================>.] - ETA: 0s - loss: 0.3275\n",
      "val/train: 1.00\n",
      "11610/11610 [==============================] - 2s 161us/sample - loss: 0.3271 - val_loss: 0.3268\n",
      "Epoch 2/10\n",
      "11296/11610 [============================>.] - ETA: 0s - loss: 0.3285\n",
      "val/train: 1.00\n",
      "11610/11610 [==============================] - 2s 143us/sample - loss: 0.3273 - val_loss: 0.3261\n",
      "Epoch 3/10\n",
      "11200/11610 [===========================>..] - ETA: 0s - loss: 0.3300\n",
      "val/train: 1.01\n",
      "11610/11610 [==============================] - 2s 139us/sample - loss: 0.3293 - val_loss: 0.3320\n",
      "Epoch 4/10\n",
      "11232/11610 [============================>.] - ETA: 0s - loss: 0.3291\n",
      "val/train: 1.00\n",
      "11610/11610 [==============================] - 2s 139us/sample - loss: 0.3296 - val_loss: 0.3284\n",
      "Epoch 5/10\n",
      "11424/11610 [============================>.] - ETA: 0s - loss: 0.3364\n",
      "val/train: 1.01\n",
      "11610/11610 [==============================] - 2s 142us/sample - loss: 0.3372 - val_loss: 0.3391\n",
      "Epoch 6/10\n",
      "11424/11610 [============================>.] - ETA: 0s - loss: 0.3309\n",
      "val/train: 1.01\n",
      "11610/11610 [==============================] - 2s 145us/sample - loss: 0.3306 - val_loss: 0.3347\n",
      "Epoch 7/10\n",
      "11520/11610 [============================>.] - ETA: 0s - loss: 0.3309\n",
      "val/train: 1.03\n",
      "11610/11610 [==============================] - 2s 141us/sample - loss: 0.3312 - val_loss: 0.3415\n",
      "Epoch 8/10\n",
      "11296/11610 [============================>.] - ETA: 0s - loss: 0.3245\n",
      "val/train: 1.02\n",
      "11610/11610 [==============================] - 2s 138us/sample - loss: 0.3241 - val_loss: 0.3302\n",
      "Epoch 9/10\n",
      "11552/11610 [============================>.] - ETA: 0s - loss: 0.3234\n",
      "val/train: 1.02\n",
      "11610/11610 [==============================] - 2s 145us/sample - loss: 0.3233 - val_loss: 0.3288\n",
      "Epoch 10/10\n",
      "11328/11610 [============================>.] - ETA: 0s - loss: 0.3215\n",
      "val/train: 1.00\n",
      "11610/11610 [==============================] - 2s 143us/sample - loss: 0.3229 - val_loss: 0.3246\n"
     ]
    }
   ],
   "source": [
    "custom_cb = PrintValTrainRatioCallback()\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid), callbacks=[custom_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorBoard can be configured to observe a log directory containing artifacts from training and prepare various visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\logs\\\\run_20200427_21-41-23'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir, 'logs')\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime('run_%Y%m%d_%H-%M-%S')\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/30\n",
      "11610/11610 [==============================] - 2s 209us/sample - loss: 0.3318 - val_loss: 0.3157\n",
      "Epoch 2/30\n",
      "11610/11610 [==============================] - 2s 180us/sample - loss: 0.3292 - val_loss: 0.3173\n",
      "Epoch 3/30\n",
      "11610/11610 [==============================] - 2s 179us/sample - loss: 0.3285 - val_loss: 0.3143\n",
      "Epoch 4/30\n",
      "11610/11610 [==============================] - 2s 180us/sample - loss: 0.3300 - val_loss: 0.3156\n",
      "Epoch 5/30\n",
      "11610/11610 [==============================] - 2s 179us/sample - loss: 0.3273 - val_loss: 0.3179\n",
      "Epoch 6/30\n",
      "11610/11610 [==============================] - 2s 180us/sample - loss: 0.3267 - val_loss: 0.3134\n",
      "Epoch 7/30\n",
      "11610/11610 [==============================] - 2s 179us/sample - loss: 0.3259 - val_loss: 0.3120\n",
      "Epoch 8/30\n",
      "11610/11610 [==============================] - 2s 180us/sample - loss: 0.3245 - val_loss: 0.3131\n",
      "Epoch 9/30\n",
      "11610/11610 [==============================] - 2s 179us/sample - loss: 0.3234 - val_loss: 0.3153\n",
      "Epoch 10/30\n",
      "11610/11610 [==============================] - 2s 181us/sample - loss: 0.3240 - val_loss: 0.3136\n",
      "Epoch 11/30\n",
      "11610/11610 [==============================] - 2s 180us/sample - loss: 0.3234 - val_loss: 0.3126\n",
      "Epoch 12/30\n",
      "11610/11610 [==============================] - 2s 181us/sample - loss: 0.3235 - val_loss: 0.3162\n",
      "Epoch 13/30\n",
      "11610/11610 [==============================] - 2s 180us/sample - loss: 0.3220 - val_loss: 0.3126\n",
      "Epoch 14/30\n",
      "11610/11610 [==============================] - 2s 179us/sample - loss: 0.3213 - val_loss: 0.3136\n",
      "Epoch 15/30\n",
      "11610/11610 [==============================] - 2s 189us/sample - loss: 0.3202 - val_loss: 0.3147\n",
      "Epoch 16/30\n",
      "11610/11610 [==============================] - 2s 197us/sample - loss: 0.3200 - val_loss: 0.3143\n",
      "Epoch 17/30\n",
      "11610/11610 [==============================] - 2s 186us/sample - loss: 0.3197 - val_loss: 0.3182\n",
      "Epoch 18/30\n",
      "11610/11610 [==============================] - 2s 195us/sample - loss: 0.3188 - val_loss: 0.3100\n",
      "Epoch 19/30\n",
      "11610/11610 [==============================] - 2s 189us/sample - loss: 0.3178 - val_loss: 0.3082\n",
      "Epoch 20/30\n",
      "11610/11610 [==============================] - 2s 183us/sample - loss: 0.3173 - val_loss: 0.3156\n",
      "Epoch 21/30\n",
      "11610/11610 [==============================] - 2s 179us/sample - loss: 0.3165 - val_loss: 0.3090\n",
      "Epoch 22/30\n",
      "11610/11610 [==============================] - 2s 189us/sample - loss: 0.3168 - val_loss: 0.3098\n",
      "Epoch 23/30\n",
      "11610/11610 [==============================] - 2s 187us/sample - loss: 0.3150 - val_loss: 0.3114\n",
      "Epoch 24/30\n",
      "11610/11610 [==============================] - 2s 184us/sample - loss: 0.3156 - val_loss: 0.3091\n",
      "Epoch 25/30\n",
      "11610/11610 [==============================] - 2s 181us/sample - loss: 0.3171 - val_loss: 0.3082\n",
      "Epoch 26/30\n",
      "11610/11610 [==============================] - 2s 191us/sample - loss: 0.3158 - val_loss: 0.3129\n",
      "Epoch 27/30\n",
      "11610/11610 [==============================] - 2s 182us/sample - loss: 0.3148 - val_loss: 0.3128\n",
      "Epoch 28/30\n",
      "11610/11610 [==============================] - 2s 178us/sample - loss: 0.3143 - val_loss: 0.3086\n",
      "Epoch 29/30\n",
      "11610/11610 [==============================] - 2s 186us/sample - loss: 0.3140 - val_loss: 0.3116\n",
      "Epoch 30/30\n",
      "11610/11610 [==============================] - 2s 193us/sample - loss: 0.3131 - val_loss: 0.3094\n"
     ]
    }
   ],
   "source": [
    "# Use the TensorBoard callback to create the artifacts\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(get_run_logdir())\n",
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid), callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning\n",
    "\n",
    "The flexibility of neural networks comes with many hyperparameters, even the most basic architecture has a number of potential adjustments:\n",
    "\n",
    "- Number of layers\n",
    "- Number of neurons in each layer\n",
    "- Activation functions\n",
    "- Weight initialization\n",
    "\n",
    "Two familiar tuning methods are grid and randomized search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to build a basic Sequential model given some hyperparameters\n",
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation='relu'))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss='mse', optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "11610/11610 [==============================] - 2s 190us/sample - loss: 1.3287 - val_loss: 0.7459\n",
      "Epoch 2/100\n",
      "11610/11610 [==============================] - 2s 142us/sample - loss: 0.5644 - val_loss: 0.5784\n",
      "Epoch 3/100\n",
      "11610/11610 [==============================] - 2s 142us/sample - loss: 0.4942 - val_loss: 1.3988\n",
      "Epoch 4/100\n",
      "11610/11610 [==============================] - 2s 143us/sample - loss: 0.4720 - val_loss: 2.0171\n",
      "Epoch 5/100\n",
      "11610/11610 [==============================] - 2s 141us/sample - loss: 0.4661 - val_loss: 1.3521\n",
      "Epoch 6/100\n",
      "11610/11610 [==============================] - 2s 144us/sample - loss: 0.4388 - val_loss: 2.4404\n",
      "Epoch 7/100\n",
      "11610/11610 [==============================] - 2s 143us/sample - loss: 0.4315 - val_loss: 0.9491\n",
      "Epoch 8/100\n",
      "11610/11610 [==============================] - 2s 142us/sample - loss: 0.4206 - val_loss: 2.7738\n",
      "Epoch 9/100\n",
      "11610/11610 [==============================] - 2s 145us/sample - loss: 0.4318 - val_loss: 0.7723\n",
      "Epoch 10/100\n",
      "11610/11610 [==============================] - 2s 143us/sample - loss: 0.4122 - val_loss: 1.2506\n",
      "Epoch 11/100\n",
      "11610/11610 [==============================] - 2s 145us/sample - loss: 0.4107 - val_loss: 2.0098\n",
      "Epoch 12/100\n",
      "11610/11610 [==============================] - 2s 147us/sample - loss: 0.4071 - val_loss: 0.4217\n",
      "Epoch 13/100\n",
      "11610/11610 [==============================] - 2s 140us/sample - loss: 0.4232 - val_loss: 2.2657\n",
      "Epoch 14/100\n",
      "11610/11610 [==============================] - 2s 144us/sample - loss: 0.4060 - val_loss: 0.9081\n",
      "Epoch 15/100\n",
      "11610/11610 [==============================] - 2s 146us/sample - loss: 0.3961 - val_loss: 0.4578\n",
      "Epoch 16/100\n",
      "11610/11610 [==============================] - 2s 143us/sample - loss: 0.3924 - val_loss: 1.6595\n",
      "Epoch 17/100\n",
      "11610/11610 [==============================] - 2s 142us/sample - loss: 0.3938 - val_loss: 0.9950\n",
      "Epoch 18/100\n",
      "11610/11610 [==============================] - 2s 143us/sample - loss: 0.3930 - val_loss: 0.3960\n",
      "Epoch 19/100\n",
      "11610/11610 [==============================] - 2s 143us/sample - loss: 0.3871 - val_loss: 2.1295\n",
      "Epoch 20/100\n",
      "11610/11610 [==============================] - 2s 143us/sample - loss: 0.3894 - val_loss: 1.1662\n",
      "Epoch 21/100\n",
      "11610/11610 [==============================] - 2s 145us/sample - loss: 0.3819 - val_loss: 0.6048\n",
      "Epoch 22/100\n",
      "11610/11610 [==============================] - 2s 141us/sample - loss: 0.3795 - val_loss: 1.5726\n",
      "Epoch 23/100\n",
      "11610/11610 [==============================] - 2s 148us/sample - loss: 0.3787 - val_loss: 1.0929\n",
      "Epoch 24/100\n",
      "11610/11610 [==============================] - 2s 145us/sample - loss: 0.3779 - val_loss: 1.6435\n",
      "Epoch 25/100\n",
      "11610/11610 [==============================] - 2s 145us/sample - loss: 0.3754 - val_loss: 1.7208\n",
      "Epoch 26/100\n",
      "11610/11610 [==============================] - 2s 145us/sample - loss: 0.3750 - val_loss: 0.3963\n",
      "Epoch 27/100\n",
      "11610/11610 [==============================] - 2s 150us/sample - loss: 0.3717 - val_loss: 1.4360\n",
      "Epoch 28/100\n",
      "11610/11610 [==============================] - 2s 147us/sample - loss: 0.3724 - val_loss: 0.5297\n",
      "5160/5160 [==============================] - 0s 77us/sample - loss: 0.3846\n"
     ]
    }
   ],
   "source": [
    "# Create a Scikit-Learn style regressor by using the KerasRegressor wrapper\n",
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n",
    "\n",
    "keras_reg.fit(\n",
    "    X_train, y_train, epochs=100, \n",
    "    validation_data=(X_valid, y_valid), \n",
    "    callbacks=[keras.callbacks.EarlyStopping(patience=10)]\n",
    ")\n",
    "mse_test = keras_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = keras_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nrnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3)\\nrnd_search_cv.fit(\\n    X_train, y_train, epochs=100, \\n    validation_data=(X_valid, y_valid),\\n    callbacks=[keras.callbacks.EarlyStopping(patience=10)]\\n)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Set the hyperparameters to check\n",
    "param_distribs = {\n",
    "    'n_hidden': [0, 1, 2, 3],\n",
    "    'n_neurons': np.arange(1, 100),\n",
    "    'learning_rate': reciprocal(3e-4, 3e-2)\n",
    "}\n",
    "\n",
    "# Perform the randomized search (warning: will take a very long time! Commented to avoid accidental execution)\n",
    "\"\"\"\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3)\n",
    "rnd_search_cv.fit(\n",
    "    X_train, y_train, epochs=100, \n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[keras.callbacks.EarlyStopping(patience=10)]\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best parameters and score\n",
    "rnd_search_cv.best_params_, rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "model = rnd_search_cv.best_estimator_.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are more efficient ways to explore a search space than randomized search, usually by starting with a faster search with a wide range of parameters and then performing more thorough searches in good regions of the search space.\n",
    "\n",
    "Some examples:\n",
    "\n",
    "- [Hyperopt](https://github.com/hyperopt/hyperopt): a popular library for optimizing over complex search spaces including both real values (such as learning rate) and discrete values (such as number of layers)\n",
    "- [Hyperas](https://github.com/maxpumperla/hyperas), [kopt](https://github.com/Avsecz/kopt), [Talos](https://github.com/autonomio/talos): useful libraries for optimmizing hyperparameters specifically for Keras models (Hyperas and kopt are based on Hyperopt)\n",
    "- [Keras Tuner](https://www.youtube.com/watch?v=Un0JDL3i5Hg&t=24s): an optimization library created by Google for Keras models with a hosted service for visualization and analysis\n",
    "- [Scikit-Optimize, or skopt](https://scikit-optimize.github.io/): a general-purpose optimization library\n",
    "- [Spearmint](https://github.com/JasperSnock/spearmint): a Bayesian optimization library\n",
    "- [Hyperband](https://github.com/zygmuntz/hyperband): a fast tuning library based on the [Hyperband paper](https://arxiv.org/abs/1603.06560) by Lisha Li et al.\n",
    "- [Sklearn-Deap](https://github.com/rsteca/sklearn-deap): an optimization library based on evolutionary algorithms with an interface similar to GridSearchCV\n",
    "\n",
    "Tuning services also exist:\n",
    "\n",
    "- [Google Cloud AI Platform](https://cloud.google.com/ai-platform/training/docs/using-hyperparameter-tuning)\n",
    "- [Arimo](https://arimo.com/)\n",
    "- [SigOpt](https://sigopt.com/)\n",
    "- [CallDesk's Oscar](http://oscar.calldesk.ai/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
