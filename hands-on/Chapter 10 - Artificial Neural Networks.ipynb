{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Artificial neural networks are models inspired by networks of biological neurons that are made up of artificial neurons that individually perform various computations.\n",
    "\n",
    "Topics:\n",
    "\n",
    "- Overview\n",
    "- Implementation\n",
    "- Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "One simple ANN architecture is the **Perceptron**, which is made up of a single layer of **threshold logic units (TLUs)**. A TLU computes a weighted sum of inputs and applies a step function to determine an output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Equation 1: Common step functions*\n",
    "\n",
    "\\begin{equation*}\n",
    "\\text{heaviside}(z) = \\begin{cases}\n",
    "0 \\;\\text{ if }\\; z \\lt t\\\\\n",
    "1 \\;\\text{ if }\\; z \\geq t\\\\\n",
    "\\end{cases}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "\\text{sgn}(z) = \\begin{cases}\\begin{aligned}\n",
    "-1 \\;\\text{ if }\\; z \\lt t\\\\\n",
    "0 \\;\\text{ if }\\; z = t\\\\\n",
    "1 \\;\\text{ if }\\; z \\geq t\\\\\n",
    "\\end{aligned}\\end{cases}\n",
    "\\end{equation*}\n",
    "\n",
    "where $t$ is some numeric threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each TLU in a Perceptron is connected to all of the inputs in the input layer, classifying the Perceptron as a **fully connected layer**. Constant inputs are referred to as **bias neurons**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Equation 2: Computing fully connected layer outputs*\n",
    "\n",
    "\\begin{equation*}\n",
    "h_\\mathbf{W},\\mathbf{b}(\\mathbf{X}) = \\phi(\\mathbf{XW}+\\mathbf{b})\n",
    "\\end{equation*}\n",
    "\n",
    "- $\\mathbf{X}$ is the matrix of input features\n",
    "- $\\mathbf{W}$ is the vector of non-bias connectionn weights\n",
    "- $\\mathbf{b}$ is the vector of bias connection weights\n",
    "- $\\phi$ is the activation function (such as a step function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a Perceptron involves adjusting the weights after making predictions on each training instance to reduce the error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Equation 3: Perceptron learning rule*\n",
    "\n",
    "\\begin{equation*}\n",
    "w_{i,j}^{\\text{next step}} = w_{i,j} + \\eta  \\bigl(y_j - \\hat{y}_j\\bigr)x_i\n",
    "\\end{equation*}\n",
    "\n",
    "- $w_{i,j}$ is the connection weight between the $i^{\\text{th}}$ input neuron and the $j^{\\text{th}}$ output neuron\n",
    "- $x_i$ is the $i^{\\text{th}}$ input value of the current training instance\n",
    "- $\\hat{y}_j$ is the output of the $j^{\\text{th}}$ output neuron for the current training instance\n",
    "- $y_j$ is the target output of the $j^{\\text{th}}$ output neuron for the current training instance\n",
    "- $\\eta$ is the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
       "           fit_intercept=True, max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "           penalty=None, random_state=0, shuffle=True, tol=0.001,\n",
       "           validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perceptron demonstration with sklearn\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "# Get petal length and width\n",
    "X = iris.data[:, (2, 3)]\n",
    "y = (iris.target == 0).astype(np.int)\n",
    "\n",
    "per_clf = Perceptron()\n",
    "per_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = per_clf.predict([[2, 0.5]])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
